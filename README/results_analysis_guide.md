# HyDL-IDS 모델 결과 분석 및 보고서 통합 가이드

이 문서는 HyDL-IDS 모델을 실행한 후 얻은 결과를 분석하고, 이를 최종 보고서에 효과적으로 통합하는 방법에 대한 상세한 가이드라인을 제공합니다. 

## 목차

1. [결과 수집 및 정리](#1-결과-수집-및-정리)
2. [학습 이력 분석](#2-학습-이력-분석)
3. [평가 지표 분석](#3-평가-지표-분석)
4. [결과 시각화](#4-결과-시각화)
5. [보고서 통합](#5-보고서-통합)
6. [추가 분석 및 인사이트](#6-추가-분석-및-인사이트)
7. [체크리스트](#7-체크리스트)

## 1. 결과 수집 및 정리

### 1.1 학습 이력 수집

`train_model.py` 실행 후 생성되는 결과 파일에서 학습 이력을 수집하세요:

- `results/[실행_타임스탬프]/metrics.json` 파일에서 학습 이력 데이터 확인
- 또는 TensorBoard 로그에서 더 상세한 학습 이력 확인 가능

**수집할 데이터:**
- 각 에포크별 학습/검증 손실(loss)
- 각 에포크별 학습/검증 정확도(accuracy)
- 각 에포크별 학습/검증 MAE, MSE 등 추가 지표
- 학습 시간
- Early Stopping 발생 여부와 발생 에포크

**결과 정리 예시:**
```python
# Python을 사용한 결과 정리 예시
import json
import pandas as pd
import matplotlib.pyplot as plt

# 결과 파일 로드
with open('results/run_20250506_121530/metrics.json', 'r') as f:
    metrics = json.load(f)

# 학습 이력을 DataFrame으로 정리
history_df = pd.DataFrame({
    'epoch': range(1, len(metrics['loss']) + 1),
    'train_loss': metrics['loss'],
    'val_loss': metrics['val_loss'],
    'train_acc': metrics['accuracy'],
    'val_acc': metrics['val_accuracy']
})

# CSV로 저장하여 나중에 참조 가능
history_df.to_csv('learning_history.csv', index=False)

# 학습 시간과 최적 에포크 확인
training_time = metrics.get('training_time', 'N/A')
best_epoch = history_df['val_acc'].idxmax() + 1  # 가장 높은 검증 정확도의 에포크
```

### 1.2 평가 지표 수집

테스트 세트에 대한 모델 평가 결과를 수집하세요:

- `results/[실행_타임스탬프]/evaluation_summary.txt` 파일에서 평가 지표 확인
- `results/[실행_타임스탬프]/metrics.json`에서 상세 지표 확인

**수집할 데이터:**
- 기본 평가 지표: 정확도(accuracy), 손실(loss), MAE, MSE
- 분류 평가 지표: 정밀도(precision), 재현율(recall), F1 점수
- 오탐지율(FPR), 미탐지율(FNR)
- 혼동 행렬 값: TP, TN, FP, FN
- 공격 유형별 성능(데이터에 공격 유형이 레이블링된 경우)

**결과 정리 예시:**
```python
# 평가 지표를 딕셔너리로 정리
evaluation_metrics = {
    'accuracy': metrics.get('accuracy', 'N/A'),
    'precision': metrics.get('precision', 'N/A'),
    'recall': metrics.get('recall', 'N/A'),
    'f1_score': metrics.get('f1_score', 'N/A'),
    'fpr': metrics.get('fpr', 'N/A'),
    'fnr': metrics.get('fnr', 'N/A'),
    'true_positives': metrics.get('true_positives', 'N/A'),
    'true_negatives': metrics.get('true_negatives', 'N/A'),
    'false_positives': metrics.get('false_positives', 'N/A'),
    'false_negatives': metrics.get('false_negatives', 'N/A')
}
```

### 1.3 시각화 결과 수집

- `results/[실행_타임스탬프]/graphs/` 디렉토리에서 모든 시각화 결과 수집
- 필요한 시각화 파일:
  - 학습 곡선(손실, 정확도)
  - 혼동 행렬
  - ROC 곡선
  - 정밀도-재현율 곡선

## 2. 학습 이력 분석

수집한 학습 이력을 분석하여 모델의 학습 과정과 특성을 파악하세요.

### 2.1 수렴 패턴 분석

```markdown
## 학습 과정 분석

HyDL-IDS 모델의 학습 과정에서 나타난 손실과 정확도의 변화를 분석했습니다.

### 수렴 패턴

학습 손실은 초기 **[초기 손실값]**에서 시작하여 **[최종 에포크]** 에포크에서 **[최종 손실값]**까지 감소했습니다. 특히 **[에포크 번호]** 에포크에서 급격한 손실 감소가 관찰되었으며, 이는 모델이 데이터의 중요한 패턴을 학습했음을 시사합니다.

검증 손실은 **[에포크 번호]** 에포크까지 지속적으로 감소하다가 이후 **[증가/정체]** 패턴을 보였습니다. 이는 모델이 **[에포크 번호]** 에포크 이후로 과적합되기 시작했을 가능성을 시사합니다.
```

**분석 시 고려할 사항:**
- 손실 감소 속도(빠른 감소 vs 점진적 감소)
- 학습/검증 손실 간의 격차(큰 격차는 과적합 가능성 시사)
- 정확도 향상 패턴(빠른 향상 vs 점진적 향상)
- 수렴 시점(몇 번째 에포크에서 안정화되었는지)

### 2.2 과적합/과소적합 평가

```markdown
### 과적합 분석

학습 정확도는 최종적으로 **[최종 학습 정확도]**에 도달했으나, 검증 정확도는 **[최종 검증 정확도]**에 머물렀습니다. 두 지표 간 **[격차 크기]**의 격차는 **[심각한/경미한/없는]** 과적합을 나타냅니다.

[옵션 1 - 과적합이 있는 경우]
과적합의 징후는 **[에포크 번호]** 에포크부터 나타나기 시작했으며, 이는 모델이 학습 데이터의 특정 패턴을 과도하게 학습하기 시작했음을 의미합니다. Early Stopping 메커니즘이 **[에포크 번호]** 에포크에서 작동하여 최적의 가중치를 저장했습니다.

[옵션 2 - 과적합이 없는 경우]
학습과 검증 정확도가 유사한 패턴으로 증가하며 큰 격차 없이 수렴했습니다. 이는 모델이 학습 데이터에 과적합되지 않고 일반화 능력을 잘 유지했음을 나타냅니다.
```

**분석 시 고려할 사항:**
- 학습/검증 지표 간 격차(큰 격차는 과적합 시사)
- 검증 손실이 증가하기 시작하는 시점
- Early Stopping이 작동한 시점과 이유
- 과적합/과소적합을 방지하기 위한 조치의 효과

### 2.3 모델 안정성 평가

```markdown
### 모델 안정성

학습 과정에서 모델의 성능 지표는 **[안정적/불안정한]** 패턴을 보였습니다. 

[옵션 1 - 안정적인 경우]
검증 정확도의 표준 편차는 약 **[표준 편차 값]**로, 에포크 간 변동이 작았습니다. 이는 모델이 다양한 데이터 샘플에 대해 일관된 성능을 보이며 학습이 안정적으로 진행되었음을 나타냅니다.

[옵션 2 - 불안정한 경우]
검증 정확도의 표준 편차는 약 **[표준 편차 값]**로, 에포크 간 상당한 변동이 관찰되었습니다. 이런 불안정성은 모델이 특정 데이터 패턴에 민감하게 반응하거나, 학습률이 너무 높게 설정되었을 가능성을 시사합니다.
```

**분석 시 고려할 사항:**
- 에포크 간 지표 변동성(안정적 vs 불안정)
- 검증 지표의 표준 편차
- 불안정성의 가능한 원인(학습률, 배치 크기, 데이터 분포 등)
- 안정성 향상을 위한 가능한 조치

## 3. 평가 지표 분석

테스트 세트에서의 평가 지표를 분석하여 모델의 실제 성능을 이해하세요.

### 3.1 기본 지표 해석

```markdown
## 테스트 세트 성능 분석

HyDL-IDS 모델의 테스트 세트에 대한 성능을 다양한 지표를 통해 분석했습니다.

### 기본 평가 지표 해석

모델은 테스트 세트에서 **[정확도 값]**의 정확도를 달성했습니다. 이는 전체 테스트 샘플 중 **[정확도 백분율]**%를 올바르게 분류했음을 의미합니다. 

손실 값은 **[손실 값]**으로, 이는 모델의 예측이 실제 레이블과 얼마나 차이가 있는지를 나타냅니다. 이 손실 값은 **[우수한/양호한/개선 필요한]** 수준으로, **[관련 해석]**을 시사합니다.

MAE(Mean Absolute Error)는 **[MAE 값]**으로, 모델 예측의 평균 절대 오차를 나타냅니다. MSE(Mean Squared Error)는 **[MSE 값]**으로, 큰 오차에 더 민감한 지표입니다. 이 값들은 **[관련 해석]**을 시사합니다.
```

**분석 시 고려할 사항:**
- 정확도와 손실 간의 관계
- 학습 세트와 테스트 세트 성능 비교
- MAE와 MSE 해석(낮을수록 우수)
- 불균형 데이터셋의 경우 정확도만으로는 불충분함을 설명

### 3.2 분류 성능 지표 해석

```markdown
### 분류 성능 지표 분석

정밀도(Precision)는 **[정밀도 값]**로, 모델이 공격으로 분류한 샘플 중 **[정밀도 백분율]**%가 실제 공격이었음을 의미합니다. 이는 모델의 오탐지율이 **[100-정밀도 백분율]**%로, **[낮은/높은]** 수준입니다.

재현율(Recall)은 **[재현율 값]**로, 실제 공격 중 **[재현율 백분율]**%를 모델이 탐지했음을 의미합니다. 이는 모델이 실제 공격의 **[100-재현율 백분율]**%를 놓치고 있음을 나타냅니다.

F1 점수는 **[F1 값]**로, 정밀도와 재현율의 조화 평균입니다. 이 점수는 **[우수한/양호한/개선 필요한]** 수준으로, 특히 불균형 데이터셋에서 모델의 전반적인 성능을 나타내는 중요한 지표입니다.

FPR(False Positive Rate)은 **[FPR 값]**로, 실제 정상 트래픽 중 **[FPR 백분율]**%를 모델이 오탐지했음을 의미합니다. FNR(False Negative Rate)은 **[FNR 값]**로, 실제 공격 중 **[FNR 백분율]**%를 모델이 정상으로 오분류했음을 의미합니다.
```

**분석 시 고려할 사항:**
- 정밀도와 재현율의 균형(trade-off 관계)
- 차량 네트워크 환경에서 FPR과 FNR의 중요성
- 불균형 데이터셋이 결과에 미치는 영향
- 목표 애플리케이션에 더 중요한 지표(보안 관점 vs 사용성 관점)

### 3.3 혼동 행렬 해석

```markdown
### 혼동 행렬 분석

혼동 행렬 분석 결과:
- 진양성(TP): **[TP 값]** - 모델이 공격을 올바르게 공격으로 분류
- 진음성(TN): **[TN 값]** - 모델이 정상 트래픽을 올바르게 정상으로 분류
- 위양성(FP): **[FP 값]** - 모델이 정상 트래픽을 잘못 공격으로 분류(오탐지)
- 위음성(FN): **[FN 값]** - 모델이 공격을 잘못 정상으로 분류(미탐지)

테스트 세트에는 총 **[TP+FN]**개의 실제 공격과 **[TN+FP]**개의 정상 트래픽이 포함되어 있습니다. 모델은 이 중 **[TP]**개의 공격을 올바르게 탐지하고, **[TN]**개의 정상 트래픽을 올바르게 분류했습니다.

특히 주목할 점은 **[FP 또는 FN 중 더 중요한 것]**입니다. **[FP/FN 중 선택]**이 **[높은/낮은]** 점은 **[관련 해석]**을 의미합니다.
```

**분석 시 고려할 사항:**
- 각 셀의 숫자와 그 의미
- 오탐지(FP)와 미탐지(FN) 중 어느 것이 더 심각한 문제인지
- 클래스 불균형이 혼동 행렬에 미치는 영향
- 혼동 행렬을 통해 파악할 수 있는 모델의 편향성

### 3.4 ROC 및 PR 곡선 해석

```markdown
### ROC 및 정밀도-재현율 곡선 분석

ROC 곡선 분석 결과, AUC(Area Under Curve)는 **[AUC 값]**로 측정되었습니다. 이 값은 모델이 무작위 분류기(AUC=0.5)보다 **[얼마나 더 나은지]** 나타냅니다. AUC가 **[관련 해석]**에 해당하는 **[우수한/양호한/개선 필요한]** 수준입니다.

정밀도-재현율 곡선에서 AP(Average Precision)는 **[AP 값]**로 계산되었습니다. 이 지표는 특히 불균형 데이터셋에서 모델의 성능을 평가하는 데 중요합니다. AP는 **[관련 해석]**을 나타내는 **[우수한/양호한/개선 필요한]** 수준입니다.

ROC 곡선의 형태는 **[가파른/완만한]** 상승을 보이며, 이는 모델이 **[높은/중간/낮은]** 임계값에서 더 효과적으로 작동함을 시사합니다. 정밀도-재현율 곡선은 **[완만한/급격한]** 감소를 보이며, 이는 **[관련 해석]**을 의미합니다.
```

**분석 시 고려할 사항:**
- AUC와 AP 값의 의미와 해석
- 곡선의 형태가 시사하는 모델 특성
- 불균형 데이터셋에서 PR 곡선의 중요성
- 최적 임계값 설정을 위한 곡선 분석

### 3.5 공격 유형별 성능 분석 (해당하는 경우)

```markdown
### 공격 유형별 성능 분석

다양한 공격 유형에 대한 모델의 탐지 성능을 분석한 결과:

1. **DoS 공격**: F1 점수 **[DoS F1]**로, 모델이 **[가장 잘/중간 정도로/가장 못]** 탐지한 공격 유형입니다. 이 유형의 특징은 **[관련 특징]**으로, 모델이 이를 **[효과적으로/충분히/제한적으로]** 학습했음을 시사합니다.

2. **Fuzzy 공격**: F1 점수 **[Fuzzy F1]**로, **[관련 해석]**을 나타냅니다. 이 유형은 **[관련 특징]**의 특성이 있어 모델의 탐지 능력에 **[긍정적/부정적]** 영향을 미쳤습니다.

3. **Spoofing Gear 공격**: F1 점수 **[Gear F1]**로, **[관련 해석]**을 나타냅니다. 이 공격은 특정 CAN ID에 집중되어 있어 모델이 **[효과적으로/제한적으로]** 패턴을 학습했습니다.

4. **Spoofing RPM 공격**: F1 점수 **[RPM F1]**로, **[관련 해석]**을 나타냅니다. 이 공격은 **[관련 특징]**의 특성으로 인해 **[탐지하기 쉬운/어려운]** 유형입니다.

공격 유형별 성능 차이의 주요 원인은 **[데이터 분포, 공격 패턴의 복잡성, 특징 표현력 등]**으로 분석됩니다. 특히 **[특정 공격 유형]**의 경우 **[관련 개선 방향]**을 통해 탐지 성능을 향상시킬 수 있을 것으로 판단됩니다.
```

**분석 시 고려할 사항:**
- 각 공격 유형의 특성과 이에 따른 탐지 난이도
- 데이터셋 내 각 공격 유형의 분포
- 특정 공격 유형에 대한 탐지 성능이 낮은 이유
- 공격 유형별 성능 향상을 위한 전략

## 4. 결과 시각화

모델 평가와 분석 결과를 효과적으로 시각화하여 보고서에 포함하세요.

### 4.1 학습 곡선 시각화

```python
# 학습 곡선 시각화 예시
import matplotlib.pyplot as plt

# 손실 곡선
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(history_df['epoch'], history_df['train_loss'], label='Training Loss')
plt.plot(history_df['epoch'], history_df['val_loss'], label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training and Validation Loss')
plt.legend()
plt.grid(True)

# 정확도 곡선
plt.subplot(1, 2, 2)
plt.plot(history_df['epoch'], history_df['train_acc'], label='Training Accuracy')
plt.plot(history_df['epoch'], history_df['val_acc'], label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Training and Validation Accuracy')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.savefig('learning_curves.png', dpi=300)
plt.close()
```

결과 보고서에 포함:

```markdown
![학습 곡선](learning_curves.png)

**그림 1.** HyDL-IDS 모델의 학습 과정에서의 손실과 정확도 변화. 왼쪽 그래프는 학습 및 검증 손실의 변화를 보여주며, 오른쪽 그래프는 학습 및 검증 정확도의 변화를 보여줍니다. **[에포크 번호]** 에포크 이후 검증 손실이 증가하기 시작하여 **[관련 해석]**을 시사합니다.
```

### 4.2 혼동 행렬 시각화

결과 보고서에 포함:

```markdown
![혼동 행렬](results/run_20250506_121530/graphs/confusion_matrix.png)

**그림 2.** HyDL-IDS 모델의 테스트 세트에 대한 혼동 행렬. 왼쪽 아래의 **[TN]**은 정상 트래픽을 정확히 분류한 수를, 오른쪽 위의 **[TP]**는 공격을 정확히 탐지한 수를 나타냅니다. 오른쪽 아래의 **[FN]**은 공격을 놓친 수를, 왼쪽 위의 **[FP]**는 오탐지 수를 나타냅니다.
```

### 4.3 ROC 및 PR 곡선 시각화

결과 보고서에 포함:

```markdown
![ROC 곡선](results/run_20250506_121530/graphs/roc_curve.png)

**그림 3.** ROC(Receiver Operating Characteristic) 곡선. 이 곡선은 다양한 임계값에 따른 진양성률(TPR)과 위양성률(FPR)의 관계를 보여줍니다. AUC 값 **[AUC 값]**은 모델의 분류 성능이 **[우수한/양호한/개선 필요한]** 수준임을 나타냅니다.

![정밀도-재현율 곡선](results/run_20250506_121530/graphs/precision_recall_curve.png)

**그림 4.** 정밀도-재현율 곡선. 이 곡선은 다양한 임계값에 따른 정밀도와 재현율의 관계를 보여줍니다. 평균 정밀도(AP) **[AP 값]**은 모델이 **[관련 해석]**함을 나타냅니다.
```

### 4.4 공격 유형별 성능 시각화 (해당하는 경우)

```python
# 공격 유형별 성능 시각화 예시
import numpy as np
import matplotlib.pyplot as plt

# 예시 데이터 (실제 데이터로 대체 필요)
attack_types = ['DoS', 'Fuzzy', 'Spoofing Gear', 'Spoofing RPM']
accuracy = [0.95, 0.92, 0.88, 0.90]
precision = [0.94, 0.90, 0.85, 0.88]
recall = [0.96, 0.88, 0.82, 0.92]
f1_score = [0.95, 0.89, 0.83, 0.90]

# 그래프 생성
x = np.arange(len(attack_types))
width = 0.2

fig, ax = plt.subplots(figsize=(12, 6))
rects1 = ax.bar(x - width*1.5, accuracy, width, label='Accuracy')
rects2 = ax.bar(x - width/2, precision, width, label='Precision')
rects3 = ax.bar(x + width/2, recall, width, label='Recall')
rects4 = ax.bar(x + width*1.5, f1_score, width, label='F1-score')

ax.set_ylabel('Score')
ax.set_title('Performance by Attack Type')
ax.set_xticks(x)
ax.set_xticklabels(attack_types)
ax.legend()
ax.grid(axis='y', linestyle='--', alpha=0.7)

# 막대 위에 값 표시
def autolabel(rects):
    for rect in rects:
        height = rect.get_height()
        ax.annotate(f'{height:.2f}',
                    xy=(rect.get_x() + rect.get_width()/2, height),
                    xytext=(0, 3),
                    textcoords="offset points",
                    ha='center', va='bottom')

autolabel(rects1)
autolabel(rects2)
autolabel(rects3)
autolabel(rects4)

plt.tight_layout()
plt.savefig('attack_type_performance.png', dpi=300)
plt.close()
```

결과 보고서에 포함:

```markdown
![공격 유형별 성능](attack_type_performance.png)

**그림 5.** 공격 유형별 HyDL-IDS 모델의 성능 비교. DoS 공격은 **[관련 해석]**, Fuzzy 공격은 **[관련 해석]**, Spoofing 공격들은 **[관련 해석]**을 보여줍니다.
```

## 5. 보고서 통합

수집하고 분석한 결과를 최종 보고서에 효과적으로 통합하세요.

### 5.1 프로젝트 보고서 템플릿 사용

제공된 `project_report_template.md` 파일을 기반으로 작업하세요:

1. 모든 `[사용자 실행 결과 필요]` 또는 유사한 표시가 있는 부분을 실제 결과로 대체합니다.
2. 그래프와 표에 대한 참조를 실제 파일 경로로 업데이트합니다.
3. 분석 내용을 결과 데이터에 맞게 조정합니다.

### 5.2 섹션별 통합 가이드

#### 5.2.1 서론 섹션

원래 내용을 유지하되, 필요에 따라 프로젝트 특정 정보로 보완하세요.

#### 5.2.2 모델 아키텍처 섹션

실제 구현된 모델의 아키텍처와 정확히 일치하는지 확인하고, 구현 과정에서 발생한 특이사항이 있다면 추가하세요.

#### 5.2.3 실험 환경 섹션

데이터셋 통계, 전처리 단계, 학습 파라미터 등을 실제 사용한 값으로 업데이트하세요.

#### 5.2.4 결과 및 분석 섹션

이 섹션은 가장 많은 업데이트가 필요합니다:

- 학습 이력 분석 결과 포함
- 평가 지표와 해석 추가
- 시각화 자료 삽입 및 참조
- 공격 유형별 성능 분석 결과 포함(해당하는 경우)

#### 5.2.5 논의 섹션

실험 결과를 바탕으로 모델의 강점, 한계점, 개선 방향을 논의하세요:

- 결과가 우수하다면 그 이유와 강점을 분석
- 결과가 미흡한 부분이 있다면 그 원인과 한계점을 분석
- 모델 성능 향상을 위한 구체적인 개선 방향 제시

#### 5.2.6 결론 섹션

전체 프로젝트의 결론을 간결하게 요약하고, 목표 달성 여부와 향후 연구 방향을 제시하세요.

## 6. 추가 분석 및 인사이트

기본적인 분석 외에 추가적인 인사이트를 도출하여 보고서의 가치를 높이세요.

### 6.1 임계값 최적화 분석

```markdown
### 임계값 최적화 분석

ROC 곡선과 정밀도-재현율 곡선 분석을 통해 최적의 분류 임계값을 탐색했습니다. 기본 임계값인 0.5에서 모델은 정밀도 **[정밀도 값]**, 재현율 **[재현율 값]**의 성능을 보였습니다.

분석 결과, 차량 보안 환경에서는 미탐지(FN)가 오탐지(FP)보다 심각한 결과를 초래할 수 있으므로, 재현율을 우선시하는 것이 바람직합니다. 임계값을 **[최적 임계값]**로 조정했을 때, 정밀도는 **[조정 후 정밀도]**로 다소 감소하지만 재현율은 **[조정 후 재현율]**로 향상되어, 공격 탐지 능력이 강화됩니다.

이는 실제 차량 환경에서 약간의 오탐지를 감수하더라도 실제 공격을 놓치지 않는 전략으로, 차량 안전을 최우선으로 하는 접근법입니다.
```

### 6.2 모델 복잡성 분석

```markdown
### 모델 복잡성 대비 성능 분석

HyDL-IDS 모델은 약 12만 개의 학습 가능 파라미터를 가지고 있으며, 이는 **[관련 분석]**한 수준의 복잡성입니다. 이 정도의 복잡성으로 모델은 **[정확도 값]**의 테스트 정확도를 달성했습니다.

추가 실험에서는 모델 크기를 50% 감소시켰을 때(약 6만 개 파라미터) 정확도는 **[감소된 모델 정확도]**로 **[미미하게/크게]** 하락했습니다. 반면, 모델 크기를 두 배로 증가시켰을 때(약 24만 개 파라미터) 정확도는 **[증가된 모델 정확도]**로 **[거의 변화 없음/약간 향상/크게 향상]**되었습니다.

이 결과는 현재 모델 복잡성이 **[최적/과도/부족]**함을 시사하며, 실제 차량 환경에서의 제한된 컴퓨팅 리소스를 고려할 때 **[관련 결론]**합니다.
```

### 6.3 실시간 탐지 가능성 분석

```markdown
### 실시간 탐지 가능성 분석

HyDL-IDS 모델의 평균 추론 시간은 단일 샘플(시퀀스) 당 **[추론 시간]** 밀리초로 측정되었습니다. 이는 차량 CAN 버스에서 일반적인 메시지 전송 주기(약 10-100ms)와 비교했을 때 **[충분히 빠른/유사한/더 느린]** 속도입니다.

시퀀스 길이(윈도우 크기)와 스트라이드 값을 고려할 때, 모델은 매 **[계산된 시간]** 마다 새로운 예측을 생성할 수 있습니다. 이는 **[안전 관련 결론]**을 의미합니다.

또한 모델을 **[최적화 방법]**를 통해 최적화하면 추론 시간을 최대 **[예상 개선 폭]**까지 단축할 수 있을 것으로 예상됩니다. 이는 차량 내 ECU의 제한된 컴퓨팅 능력을 고려할 때 중요한 최적화 방향입니다.
```

### 6.4 공격 유형간 혼동 분석 (해당하는 경우)

```markdown
### 공격 유형간 혼동 분석

다중 클래스 혼동 행렬 분석 결과, HyDL-IDS 모델은 특정 공격 유형들 사이에서 혼동하는 경향이 관찰되었습니다.

특히 Spoofing Gear 공격과 Spoofing RPM 공격 사이에서 **[혼동 비율]**%의 혼동이 발생했으며, 이는 두 공격이 유사한 CAN ID 범위와 패턴을 사용하기 때문으로 분석됩니다.

반면, DoS 공격과 Fuzzy 공격은 특성이 뚜렷이 구분되어 서로 혼동되는 경우가 **[혼동 비율]**%로 매우 낮았습니다.

이러한 공격 유형간 혼동은 실제 방어 메커니즘 구현 시 고려해야 할 중요한 요소입니다. 각 공격 유형별 방어 전략이 다를 수 있으므로, 정확한 유형 분류가 효과적인 대응에 중요합니다.
```

## 7. 체크리스트

결과 분석과 보고서 통합이 완료된 후 다음 체크리스트를 통해 품질을 확인하세요:

- [ ] 모든 `[사용자 실행 결과 필요]` 표시가 실제 데이터로 대체되었는가?
- [ ] 모든 그래프와 시각화 자료가 올바르게 포함되었는가?
- [ ] 결과 분석이 데이터에 기반하여 객관적으로 이루어졌는가?
- [ ] 분석 내용이 논리적이고 타당한가?
- [ ] 긍정적 결과뿐 아니라 한계점도 정직하게 보고되었는가?
- [ ] 개선 방향이 구체적이고 실현 가능한가?
- [ ] 보고서 형식이 일관되게 유지되는가?
- [ ] 문법, 철자, 표현에 오류가 없는가?